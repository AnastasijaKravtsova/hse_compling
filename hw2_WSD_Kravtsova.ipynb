{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Спонсор данной тетрадки: ctrl-c + ctrl-v. Как говорится, done than better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from string import punctuation\n",
    "\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Токенизируем без стоп-слов\"\"\"\n",
    "    words = [word.strip(punct) for word in text.lower().split() if word and word not in stops]\n",
    "    words = [word for word in words if word]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus_eng.txt', encoding='utf8') as inf:\n",
    "    data = \" \".join(x.strip() for x in inf)\n",
    "# Разобьем корпус на предложения\n",
    "split_data = sent_tokenize(data)\n",
    "# Найдём предложения с break\n",
    "break_sents = [x for x in split_data if ' break ' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Случайным образом выберем 10 предложений, содержащих break, и зафиксируем их в переменной random_sents.\n",
    "# А далее закомментируем случайный выбор, чтобы не генерить разные выборки при разных запусках.\n",
    "#random_break_sents = random.sample(break_sents, 10)\n",
    "#random_break_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sents = ['In carving out a separate entity, Credit Suisse also fulfills a regulatory requirement to make banks easier to break up in a crisis, the bank said in a statement Monday.',\n",
    " 'Study hard, but be sure to have a break time to time.',\n",
    " 'Prestemon also added that, regardless of the way wildfire patterns change in the future, human populations will almost certainly continue to increase, meaning that “t here will be more and more people exposed to the fires that occur.” For now, welcome downpours on Monday night and Tuesday helped break the dry streak in parts of the Southeast, including the Gatlinburg area, and helped suppress some of the fires.',\n",
    " \"; sees 2016 adjusted ebitda between a loss of $35 million and loss of $43 million * Ondeck reports third quarter 2016 financial results * Q3 adjusted loss per share $0.18 * Q3 gaap loss per share $0.23 * Q3 earnings per share view $-0.16 -- Thomson Reuters I/B/E/S Source text for Eikon: Further company coverage: Next In Market News Ever dig a hole in your yard as a kid, convinced you'd somehow break all the way through the Earth and end up in China/Atlantis/Narnia/Your Favorite Land Here?\",\n",
    " 'The new venture will get under way publicly after the Thanksgiving break with events at the upcoming Art Basel in Miami Beach during the first week of December.',\n",
    " 'After losing 1-0 to Iran in their last qualifier, Stielike was delighted his side had managed to break down the stingy Uzbek defence, which had conceded just two goals in their last seven matches.',\n",
    " 'Donald Trump has a much narrower path — he has to run the table in toss-up states and break through in a state that currently leans toward Clinton.',\n",
    " 'The first was during the Question Time that came live from Wembley, when she interrupted some military posturing by Boris to sniff: “ I think I’m the only one on this panel who’s ever worn the Queen’s uniform.” The next saw her decline to even break stride as a reporter asked her about Boris crashing out of the race to succeed David Cameron, only smiling lightly that, “Leadership is hard.',\n",
    " 'We can’t wait to see what the show has in store for her next–as long as it’s a storyline allowing her to FINALLY catch a break because she could seriously use one.',\n",
    " 'Anything to keep them away from the really contentious November conversation that could break out between them.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У break 75 значений, из них 16 именных и 59 глагольных\n",
      "break_0 - some abrupt occurrence that interrupts an ongoing activity\n",
      "break_1 - an unexpected piece of good luck\n",
      "break_2 - (geology) a crack in the earth's crust resulting from the displacement of one side with respect to the other\n",
      "break_3 - a personal or social separation (as between opposing factions)\n",
      "break_4 - a pause from doing something (as work)\n",
      "break_5 - the act of breaking something\n",
      "break_6 - a time interval during which there is a temporary cessation of something\n",
      "break_7 - breaking of hard tissue such as bone\n",
      "break_8 - the occurrence of breaking\n",
      "break_9 - an abrupt change in the tone or register of the voice (as at puberty or due to emotion)\n",
      "break_10 - the opening shot that scatters the balls in billiards or pool\n",
      "break_11 - (tennis) a score consisting of winning a game when your opponent was serving\n",
      "break_12 - an act of delaying or interrupting the continuity\n",
      "break_13 - a sudden dash\n",
      "break_14 - any frame in which a bowler fails to make a strike or spare\n",
      "break_15 - an escape from jail\n",
      "break_16 - terminate\n",
      "break_17 - become separated into pieces or fragments\n",
      "break_18 - render inoperable or ineffective\n",
      "break_19 - ruin completely\n",
      "break_20 - destroy the integrity of; usually by force; cause to separate into pieces or fragments\n",
      "break_21 - act in disregard of laws, rules, contracts, or promises\n",
      "break_22 - move away or escape suddenly\n",
      "break_23 - scatter or part\n",
      "break_24 - force out or release suddenly and often violently something pent up\n",
      "break_25 - prevent completion\n",
      "break_26 - enter someone's (virtual or real) property in an unauthorized manner, usually with the intent to steal or commit a violent act\n",
      "break_27 - make submissive, obedient, or useful\n",
      "break_28 - fail to agree with; be in violation of; as of rules or patterns\n",
      "break_29 - surpass in excellence\n",
      "break_30 - make known to the public information that was previously known only to a few people or that was meant to be kept a secret\n",
      "break_31 - come into being\n",
      "break_32 - stop operating or functioning\n",
      "break_33 - interrupt a continued activity\n",
      "break_34 - make a rupture in the ranks of the enemy or one's own by quitting or fleeing\n",
      "break_35 - curl over and fall apart in surf or foam, of waves\n",
      "break_36 - lessen in force or effect\n",
      "break_37 - be broken in\n",
      "break_38 - come to an end\n",
      "break_39 - vary or interrupt a uniformity or continuity\n",
      "break_40 - cause to give up a habit\n",
      "break_41 - give up\n",
      "break_42 - come forth or begin from a state of latency\n",
      "break_43 - happen or take place\n",
      "break_44 - cause the failure or ruin of\n",
      "break_45 - invalidate by judicial action\n",
      "break_46 - discontinue an association or relation; go different ways\n",
      "break_47 - assign to a lower position; reduce in rank\n",
      "break_48 - reduce to bankruptcy\n",
      "break_49 - change directions suddenly\n",
      "break_50 - emerge from the surface of a body of water\n",
      "break_51 - break down, literally or metaphorically\n",
      "break_52 - do a break dance\n",
      "break_53 - exchange for smaller units of money\n",
      "break_54 - destroy the completeness of a set of related items\n",
      "break_55 - make the opening shot that scatters the balls\n",
      "break_56 - separate from a clinch, in boxing\n",
      "break_57 - go to pieces\n",
      "break_58 - break a piece from a whole\n",
      "break_59 - become punctured or penetrated\n",
      "break_60 - pierce or penetrate\n",
      "break_61 - be released or become known; of news\n",
      "break_62 - cease an action temporarily\n",
      "break_63 - interrupt the flow of current in\n",
      "break_64 - undergo breaking\n",
      "break_65 - find a flaw in\n",
      "break_66 - find the solution or key to\n",
      "break_67 - change suddenly from one tone quality or register to another\n",
      "break_68 - happen\n",
      "break_69 - become fractured; break or crack on the surface only\n",
      "break_70 - crack; of the male voice in puberty\n",
      "break_71 - fall sharply\n",
      "break_72 - fracture a bone of\n",
      "break_73 - diminish or discontinue abruptly\n",
      "break_74 - weaken or destroy in spirit or body\n"
     ]
    }
   ],
   "source": [
    "# Давайте посмотрим на то, сколько значений может быть у break и какие они.\n",
    "word = 'break'\n",
    "print(\"У break {} значений, из них {} именных и {} глагольных\".format(len(wn.synsets(word)), len(wn.synsets(word, pos='n')),\\\n",
    "                                                                       len(wn.synsets(word, pos='v'))))\n",
    "for i, synset in enumerate(wn.synsets(word)):\n",
    "    print(word + '_' + str(i) + ' - ' + synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многовато... однако (спустя пару часов с переводчиком и тезаурусом) всё же попробуем зафиксировать некоторый золотой стандарт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_break = ['break_48', ('break_4', 'break_6'), 'break_38', 'break_60', ('break_4', 'break_6'),\\\n",
    "              'break_51', 'break_60', 'break_62', 'break_2', 'break_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Study hard, but be sure to have a break time t...</td>\n",
       "      <td>[study, hard, sure, break, time, time]</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We can’t wait to see what the show has in stor...</td>\n",
       "      <td>[can’t, wait, see, show, store, next–as, long,...</td>\n",
       "      <td>break_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "1  Study hard, but be sure to have a break time t...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "8  We can’t wait to see what the show has in stor...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "1             [study, hard, sure, break, time, time]  (break_4, break_6)   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "8  [can’t, wait, see, show, store, next–as, long,...             break_2   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "5                  \n",
       "6                  \n",
       "7                  \n",
       "8                  \n",
       "9                  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_corpus = [tokenize(sent) for sent in random_sents]\n",
    "df = pd.DataFrame({'Sentence': random_sents, 'Tokenized sentence': break_corpus, 'True sense': true_break, 'Predicted sense': ''})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_context(words, window=3):\n",
    "    \"\"\" Функция, достающая для каждого слова в списке его контекст (3 слова слева, 3 слова справа) \"\"\"\n",
    "    words_in_context = []\n",
    "    for i in range(len(words)):\n",
    "        left = words[max(0,i-window):i] \n",
    "        right = words[i+1:i+window+1]\n",
    "        target = words[i]\n",
    "        words_in_context.append((target, left+right)) \n",
    "    return words_in_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk_defs(word, sentence):\n",
    "    \"\"\"Алгоритм Леска (с определениями, базовая реализация с семинара)\"\"\"\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        definition = tokenize(synset.definition())\n",
    "        definition = set(definition)\n",
    "        sentence = set(sentence)\n",
    "        overlap = len(definition&sentence)\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "    return bestsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    # пройдем по корпусу\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        words_in_context = get_words_in_context(text)\n",
    "        # дизамбигуируем\n",
    "        for word, context in words_in_context:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_defs(word, context)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Study hard, but be sure to have a break time t...</td>\n",
       "      <td>[study, hard, sure, break, time, time]</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We can’t wait to see what the show has in stor...</td>\n",
       "      <td>[can’t, wait, see, show, store, next–as, long,...</td>\n",
       "      <td>break_2</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "1  Study hard, but be sure to have a break time t...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "8  We can’t wait to see what the show has in stor...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "1             [study, hard, sure, break, time, time]  (break_4, break_6)   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "8  [can’t, wait, see, show, store, next–as, long,...             break_2   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "1       [break_6]  \n",
       "2       [break_0]  \n",
       "3      [break_38]  \n",
       "4       [break_0]  \n",
       "5       [break_2]  \n",
       "6      [break_42]  \n",
       "7       [break_0]  \n",
       "8       [break_0]  \n",
       "9       [break_0]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_break = get_meanings(df['Tokenized sentence'])\n",
    "df['Predicted sense'] = predicted_break\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We can’t wait to see what the show has in stor...</td>\n",
       "      <td>[can’t, wait, see, show, store, next–as, long,...</td>\n",
       "      <td>break_2</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "8  We can’t wait to see what the show has in stor...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "8  [can’t, wait, see, show, store, next–as, long,...             break_2   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2       [break_0]  \n",
       "3      [break_38]  \n",
       "4       [break_0]  \n",
       "5       [break_2]  \n",
       "6      [break_42]  \n",
       "7       [break_0]  \n",
       "8       [break_0]  \n",
       "9       [break_0]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Верно определилось 1 значение из 10 -- хотя бы что-то. Удалим строку с верно определившимся значением.\n",
    "df = df.drop([1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем увеличить размер окна до 5.\n",
    "def get_words_in_context(words, window=5):\n",
    "    \"\"\" Функция, достающая для каждого слова в списке его контекст (5 слов слева, 5 слов справа) \"\"\"\n",
    "    words_in_context = []\n",
    "    for i in range(len(words)):\n",
    "        left = words[max(0,i-window):i] \n",
    "        right = words[i+1:i+window+1]\n",
    "        target = words[i]\n",
    "        words_in_context.append((target, left+right)) \n",
    "    return words_in_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We can’t wait to see what the show has in stor...</td>\n",
       "      <td>[can’t, wait, see, show, store, next–as, long,...</td>\n",
       "      <td>break_2</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "8  We can’t wait to see what the show has in stor...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "8  [can’t, wait, see, show, store, next–as, long,...             break_2   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2       [break_0]  \n",
       "3      [break_38]  \n",
       "4       [break_0]  \n",
       "5       [break_2]  \n",
       "6      [break_42]  \n",
       "7       [break_0]  \n",
       "8       [break_2]  \n",
       "9       [break_0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_break = get_meanings(df['Tokenized sentence'])\n",
    "df['Predicted sense'] = predicted_break\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2       [break_0]  \n",
       "3      [break_38]  \n",
       "4       [break_0]  \n",
       "5       [break_2]  \n",
       "6      [break_42]  \n",
       "7       [break_0]  \n",
       "9       [break_0]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Второй пошел!\n",
    "df = df.drop([8])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь попробуем вместо определений взять только примеры.\n",
    "def lesk_exmps(word, sentence):\n",
    "    \"\"\"Алгоритм Леска (с примерами)\"\"\"\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        examples = []\n",
    "        for example in synset.examples():\n",
    "            examples.extend(tokenize(example))\n",
    "        sentence = set(sentence)\n",
    "        examples = set(examples)\n",
    "        overlap = len(sentence&examples)\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "    return bestsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_44]  \n",
       "2      [break_16]  \n",
       "3      [break_32]  \n",
       "4      [break_32]  \n",
       "5      [break_11]  \n",
       "6       [break_0]  \n",
       "7       [break_0]  \n",
       "9       [break_0]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    # пройдем по корпусу\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        words_in_context = get_words_in_context(text)\n",
    "        # дизамбигуируем\n",
    "        for word, context in words_in_context:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_exmps(word, context)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus\n",
    "\n",
    "predicted_break = get_meanings(df['Tokenized sentence'])\n",
    "df['Predicted sense'] = predicted_break\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь попробуем взять и определения, и примеры.\n",
    "def lesk_defs_exmps(word, sentence):\n",
    "    \"\"\"Алгоритм Леска (с определениями и примерами)\"\"\"\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        defs_and_exmps = []\n",
    "        for example in synset.examples():\n",
    "            defs_and_exmps.extend(tokenize(example))\n",
    "        definition = tokenize(synset.definition())\n",
    "        defs_and_exmps.extend(definition)\n",
    "        sentence = set(sentence)\n",
    "        defs_and_exmps = set(defs_and_exmps)\n",
    "        overlap = len(sentence&defs_and_exmps)\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "    return bestsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[carving, separate, entity, credit, suisse, al...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, way...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, loss, 35, milli...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[new, venture, get, way, publicly, thanksgivin...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[losing, 1-0, iran, last, qualifier, stielike,...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, much, narrower, path, run, tab...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[first, question, time, came, live, wembley, i...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, keep, away, really, contentious, no...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [carving, separate, entity, credit, suisse, al...            break_48   \n",
       "2  [prestemon, also, added, that, regardless, way...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, loss, 35, milli...            break_60   \n",
       "4  [new, venture, get, way, publicly, thanksgivin...  (break_4, break_6)   \n",
       "5  [losing, 1-0, iran, last, qualifier, stielike,...            break_51   \n",
       "6  [donald, trump, much, narrower, path, run, tab...            break_60   \n",
       "7  [first, question, time, came, live, wembley, i...            break_62   \n",
       "9  [anything, keep, away, really, contentious, no...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2      [break_16]  \n",
       "3      [break_32]  \n",
       "4      [break_32]  \n",
       "5       [break_2]  \n",
       "6      [break_42]  \n",
       "7       [break_0]  \n",
       "9       [break_0]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    # пройдем по корпусу\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        words_in_context = get_words_in_context(text)\n",
    "        # дизамбигуируем\n",
    "        for word, context in words_in_context:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_defs_exmps(word, context)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus\n",
    "\n",
    "predicted_break = get_meanings(df['Tokenized sentence'])\n",
    "df['Predicted sense'] = predicted_break\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[in, carving, out, a, separate, entity, credit...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, added, that, regardless, of,...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[sees, 2016, adjusted, ebitda, between, a, los...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[the, new, venture, will, get, under, way, pub...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[after, losing, 1-0, to, iran, in, their, last...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, has, a, much, narrower, path, ...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[the, first, was, during, the, question, time,...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anything, to, keep, them, away, from, the, re...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_30]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [in, carving, out, a, separate, entity, credit...            break_48   \n",
       "2  [prestemon, also, added, that, regardless, of,...            break_38   \n",
       "3  [sees, 2016, adjusted, ebitda, between, a, los...            break_60   \n",
       "4  [the, new, venture, will, get, under, way, pub...  (break_4, break_6)   \n",
       "5  [after, losing, 1-0, to, iran, in, their, last...            break_51   \n",
       "6  [donald, trump, has, a, much, narrower, path, ...            break_60   \n",
       "7  [the, first, was, during, the, question, time,...            break_62   \n",
       "9  [anything, to, keep, them, away, from, the, re...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2      [break_26]  \n",
       "3      [break_21]  \n",
       "4      [break_32]  \n",
       "5       [break_2]  \n",
       "6       [break_0]  \n",
       "7       [break_9]  \n",
       "9      [break_30]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Некоторые значения перестали быть нулевыми, что хорошо.\n",
    "# Попробуем поиграться со стоп-словами: возможно, если вернуть их в датасет, то они укажут на верную семантику?\n",
    "\n",
    "def tokenize_stops(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split() if word]\n",
    "    words = [word for word in words if word]\n",
    "\n",
    "    return words\n",
    "\n",
    "break_corpus_stops = [tokenize_stops(x) for x in df['Sentence']]\n",
    "df_stops = pd.DataFrame({'Sentence': df['Sentence'], 'Tokenized sentence': break_corpus_stops, 'True sense': df['True sense'], 'Predicted sense': ''})\n",
    "\n",
    "def lesk_defs_exmps_stops(word, sentence):\n",
    "    \"\"\"Алгоритм Леска (с определениями и примерами)\"\"\"\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        defs_and_exmps = []\n",
    "        for example in synset.examples():\n",
    "            defs_and_exmps.extend(tokenize_stops(example))\n",
    "        definition = tokenize_stops(synset.definition())\n",
    "        defs_and_exmps.extend(definition)\n",
    "        sentence = set(sentence)\n",
    "        defs_and_exmps = set(defs_and_exmps)\n",
    "        overlap = len(sentence&defs_and_exmps)\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "    return bestsense\n",
    "\n",
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    # пройдем по корпусу\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        words_in_context = get_words_in_context(text)\n",
    "        # дизамбигуируем\n",
    "        for word, context in words_in_context:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_defs_exmps_stops(word, context)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus\n",
    "\n",
    "predicted_break = get_meanings(df_stops['Tokenized sentence'])\n",
    "df_stops['Predicted sense'] = predicted_break\n",
    "df_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[in, carv, out, a, separ, entiti, credit, suis...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, ad, that, regardless, of, th...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[see, 2016, adjust, ebitda, between, a, loss, ...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[the, new, ventur, will, get, under, way, publ...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[after, lose, 1-0, to, iran, in, their, last, ...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, ha, a, much, narrow, path, he,...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[the, first, wa, dure, the, question, time, th...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anyth, to, keep, them, away, from, the, reall...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_30]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [in, carv, out, a, separ, entiti, credit, suis...            break_48   \n",
       "2  [prestemon, also, ad, that, regardless, of, th...            break_38   \n",
       "3  [see, 2016, adjust, ebitda, between, a, loss, ...            break_60   \n",
       "4  [the, new, ventur, will, get, under, way, publ...  (break_4, break_6)   \n",
       "5  [after, lose, 1-0, to, iran, in, their, last, ...            break_51   \n",
       "6  [donald, trump, ha, a, much, narrow, path, he,...            break_60   \n",
       "7  [the, first, wa, dure, the, question, time, th...            break_62   \n",
       "9  [anyth, to, keep, them, away, from, the, reall...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2      [break_26]  \n",
       "3      [break_21]  \n",
       "4      [break_32]  \n",
       "5       [break_2]  \n",
       "6       [break_0]  \n",
       "7       [break_9]  \n",
       "9      [break_30]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удалось сделать еще одно значение ненулевым.\n",
    "# Попробуем прикрутить стемминг, который по идее для английского сработает лучше, нежели лемматизация.\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def normalize(text):\n",
    "    stems = [stemmer.stem(x) for x in text]\n",
    "    return stems\n",
    "\n",
    "break_corpus_stops_stems = [normalize(tokenize_stops(x)) for x in df_stops['Sentence']]\n",
    "df_stops_stems = pd.DataFrame({'Sentence': df_stops['Sentence'], 'Tokenized sentence': break_corpus_stops_stems, \\\n",
    "                               'True sense': df_stops['True sense'], 'Predicted sense': ''})\n",
    "\n",
    "# Добавим стемминг в алгоритм Леска.\n",
    "def lesk_defs_exmps_stops_stems(word, sentence):\n",
    "    \"\"\"Алгоритм Леска (с определениями и примерами)\"\"\"\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    for i, synset in enumerate(wn.synsets(word)):\n",
    "        defs_and_exmps = []\n",
    "        for example in synset.examples():\n",
    "            defs_and_exmps.extend(normalize(tokenize_stops(example)))\n",
    "        definition = normalize(tokenize_stops(synset.definition()))\n",
    "        defs_and_exmps.extend(definition)\n",
    "        sentence = set(sentence)\n",
    "        defs_and_exmps = set(defs_and_exmps)\n",
    "        overlap = len(sentence&defs_and_exmps)\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "    return bestsense\n",
    "\n",
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    # пройдем по корпусу\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        words_in_context = get_words_in_context(text)\n",
    "        # дизамбигуируем\n",
    "        for word, context in words_in_context:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_defs_exmps_stops_stems(word, context)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus\n",
    "\n",
    "predicted_break = get_meanings(df_stops_stems['Tokenized sentence'])\n",
    "df_stops_stems['Predicted sense'] = predicted_break\n",
    "df_stops_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[in, carv, out, a, separ, entiti, credit, suis...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, ad, that, regardless, of, th...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[see, 2016, adjust, ebitda, between, a, loss, ...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[the, new, ventur, will, get, under, way, publ...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[after, lose, 1-0, to, iran, in, their, last, ...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, ha, a, much, narrow, path, he,...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[the, first, wa, dure, the, question, time, th...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anyth, to, keep, them, away, from, the, reall...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [in, carv, out, a, separ, entiti, credit, suis...            break_48   \n",
       "2  [prestemon, also, ad, that, regardless, of, th...            break_38   \n",
       "3  [see, 2016, adjust, ebitda, between, a, loss, ...            break_60   \n",
       "4  [the, new, ventur, will, get, under, way, publ...  (break_4, break_6)   \n",
       "5  [after, lose, 1-0, to, iran, in, their, last, ...            break_51   \n",
       "6  [donald, trump, ha, a, much, narrow, path, he,...            break_60   \n",
       "7  [the, first, wa, dure, the, question, time, th...            break_62   \n",
       "9  [anyth, to, keep, them, away, from, the, reall...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2       [break_9]  \n",
       "3      [break_11]  \n",
       "4       [break_9]  \n",
       "5      [break_14]  \n",
       "6      [break_30]  \n",
       "7      [break_30]  \n",
       "9       [break_4]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Попробуем взять просто алгоритм Леска, без контекстного окна.\n",
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        for word in text:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_defs_exmps_stops_stems(word, text)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus\n",
    "\n",
    "predicted_break = get_meanings(df_stops_stems['Tokenized sentence'])\n",
    "df_stops_stems['Predicted sense'] = predicted_break\n",
    "df_stops_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized sentence</th>\n",
       "      <th>True sense</th>\n",
       "      <th>Predicted sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In carving out a separate entity, Credit Suiss...</td>\n",
       "      <td>[in, carv, out, a, separ, entiti, credit, suis...</td>\n",
       "      <td>break_48</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestemon also added that, regardless of the w...</td>\n",
       "      <td>[prestemon, also, ad, that, regardless, of, th...</td>\n",
       "      <td>break_38</td>\n",
       "      <td>[break_26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>; sees 2016 adjusted ebitda between a loss of ...</td>\n",
       "      <td>[see, 2016, adjust, ebitda, between, a, loss, ...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new venture will get under way publicly af...</td>\n",
       "      <td>[the, new, ventur, will, get, under, way, publ...</td>\n",
       "      <td>(break_4, break_6)</td>\n",
       "      <td>[break_9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After losing 1-0 to Iran in their last qualifi...</td>\n",
       "      <td>[after, lose, 1-0, to, iran, in, their, last, ...</td>\n",
       "      <td>break_51</td>\n",
       "      <td>[break_14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald Trump has a much narrower path — he has...</td>\n",
       "      <td>[donald, trump, ha, a, much, narrow, path, he,...</td>\n",
       "      <td>break_60</td>\n",
       "      <td>[break_30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The first was during the Question Time that ca...</td>\n",
       "      <td>[the, first, wa, dure, the, question, time, th...</td>\n",
       "      <td>break_62</td>\n",
       "      <td>[break_7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anything to keep them away from the really con...</td>\n",
       "      <td>[anyth, to, keep, them, away, from, the, reall...</td>\n",
       "      <td>break_24</td>\n",
       "      <td>[break_4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  In carving out a separate entity, Credit Suiss...   \n",
       "2  Prestemon also added that, regardless of the w...   \n",
       "3  ; sees 2016 adjusted ebitda between a loss of ...   \n",
       "4  The new venture will get under way publicly af...   \n",
       "5  After losing 1-0 to Iran in their last qualifi...   \n",
       "6  Donald Trump has a much narrower path — he has...   \n",
       "7  The first was during the Question Time that ca...   \n",
       "9  Anything to keep them away from the really con...   \n",
       "\n",
       "                                  Tokenized sentence          True sense  \\\n",
       "0  [in, carv, out, a, separ, entiti, credit, suis...            break_48   \n",
       "2  [prestemon, also, ad, that, regardless, of, th...            break_38   \n",
       "3  [see, 2016, adjust, ebitda, between, a, loss, ...            break_60   \n",
       "4  [the, new, ventur, will, get, under, way, publ...  (break_4, break_6)   \n",
       "5  [after, lose, 1-0, to, iran, in, their, last, ...            break_51   \n",
       "6  [donald, trump, ha, a, much, narrow, path, he,...            break_60   \n",
       "7  [the, first, wa, dure, the, question, time, th...            break_62   \n",
       "9  [anyth, to, keep, them, away, from, the, reall...            break_24   \n",
       "\n",
       "  Predicted sense  \n",
       "0      [break_14]  \n",
       "2      [break_26]  \n",
       "3       [break_9]  \n",
       "4       [break_9]  \n",
       "5      [break_14]  \n",
       "6      [break_30]  \n",
       "7       [break_7]  \n",
       "9       [break_4]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Виден прогресс: теперь нет нулевых значений + для предложений 4 и 7 значение перешло в нужную часть речи.\n",
    "# Попробуем взять просто алгоритм Леска, без контекстного окна.\n",
    "def get_meanings(corpus):\n",
    "    dis_corpus = []\n",
    "    for text in corpus:\n",
    "        dis_text = []\n",
    "        for word in text:\n",
    "            if word == 'break':\n",
    "                nsense = lesk_defs_exmps_stops(word, text)\n",
    "                dis_text.append(word + '_' + str(nsense))\n",
    "        dis_corpus.append(dis_text)\n",
    "    return dis_corpus\n",
    "\n",
    "predicted_break = get_meanings(df_stops_stems['Tokenized sentence'])\n",
    "df_stops_stems['Predicted sense'] = predicted_break\n",
    "df_stops_stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно продолжать процесс перебора сочетаний параметров, однако, судя по всему, это не приведет ни к чему более выдающемуся, поэтому подведем итоги:\n",
    "\n",
    "1) Верно удалось определить значения *break* в 2-х предложениях из 10.\n",
    "\n",
    "2) В качестве методов оптимизации были использованы:\n",
    "- расширение контекстного окна\n",
    "- учет определений/примеров/определений и примеров\n",
    "- возврат в выборку стоп-слов (как ни странно, с ними работало лучше -- думаю, вещи вроде артикля в данном случае служат хорошую службу, указывая на ЧР для слова, значение которого мы определяем)\n",
    "- стемминг\n",
    "- алгоритм Леска для всего предложения без учета контекста\n",
    "\n",
    "3) Основные промахи произошли, на мой взгляд, по следующим причинам:\n",
    "- в ворднете представлены не все интересующие нас значения: например, я так и не обнаружила в нем вполне частотного значения \"преодолеть\" (overpass), которое очень хотелось приписать в двух предложениях выборки (2 и 6) выборки\n",
    "- малое количество примеров и их скудный вид"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
